{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KMubAwwP04G"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-XZm7sajbmM",
    "outputId": "bb0721c6-14f5-4d0f-9ee6-ba68d0383d58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py==1.4.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: accelerate==0.22.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (0.22.0)\n",
      "Requirement already satisfied: amqp==5.1.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (5.1.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.6.3)\n",
      "Requirement already satisfied: async-timeout==4.0.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (4.0.3)\n",
      "Requirement already satisfied: billiard==4.1.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (4.1.0)\n",
      "Requirement already satisfied: bio==1.5.9 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (1.5.9)\n",
      "Requirement already satisfied: biopython==1.81 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (1.81)\n",
      "Requirement already satisfied: biothings-client==0.3.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (0.3.0)\n",
      "Requirement already satisfied: biotite==0.37.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (0.37.0)\n",
      "Requirement already satisfied: blinker==1.6.2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (1.6.2)\n",
      "Requirement already satisfied: blosum in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (2.0.2)\n",
      "Requirement already satisfied: cachetools==5.3.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (5.3.1)\n",
      "Requirement already satisfied: celery==5.3.4 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 14)) (5.3.4)\n",
      "Requirement already satisfied: certifi==2023.7.22 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 15)) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer==3.2.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 16)) (3.2.0)\n",
      "Requirement already satisfied: click==8.1.7 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 17)) (8.1.7)\n",
      "Requirement already satisfied: click-didyoumean==0.3.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 18)) (0.3.0)\n",
      "Requirement already satisfied: click-plugins==1.1.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 19)) (1.1.1)\n",
      "Requirement already satisfied: click-repl==0.3.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 20)) (0.3.0)\n",
      "Requirement already satisfied: cmake==3.27.4.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 21)) (3.27.4.1)\n",
      "Requirement already satisfied: fair-esm==2.0.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 22)) (2.0.0)\n",
      "Requirement already satisfied: filelock==3.12.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 23)) (3.12.3)\n",
      "Requirement already satisfied: Flask==2.3.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 24)) (2.3.3)\n",
      "Requirement already satisfied: Flask-Mail==0.9.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 25)) (0.9.1)\n",
      "Requirement already satisfied: Flask-WTF==1.1.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 26)) (1.1.1)\n",
      "Requirement already satisfied: flatbuffers==23.5.26 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 27)) (23.5.26)\n",
      "Requirement already satisfied: fsspec==2023.9.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 28)) (2023.9.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 29)) (0.4.0)\n",
      "Requirement already satisfied: google-auth==2.22.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 30)) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib==1.0.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 31)) (1.0.0)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 32)) (0.2.0)\n",
      "Requirement already satisfied: gprofiler-official==1.0.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 33)) (1.0.0)\n",
      "Requirement already satisfied: grpcio==1.58.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 34)) (1.58.0)\n",
      "Requirement already satisfied: h5py==3.9.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 35)) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub==0.16.4 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 36)) (0.16.4)\n",
      "Requirement already satisfied: idna==3.4 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 37)) (3.4)\n",
      "Requirement already satisfied: install==1.3.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 38)) (1.3.5)\n",
      "Requirement already satisfied: itsdangerous==2.1.2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 39)) (2.1.2)\n",
      "Requirement already satisfied: jax==0.4.13 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 40)) (0.4.13)\n",
      "Requirement already satisfied: Jinja2==3.1.2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 41)) (3.1.2)\n",
      "Requirement already satisfied: keras==2.12.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 42)) (2.12.0)\n",
      "Requirement already satisfied: kombu==5.3.2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 43)) (5.3.2)\n",
      "Requirement already satisfied: libclang==16.0.6 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 44)) (16.0.6)\n",
      "Requirement already satisfied: lit==16.0.6 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 45)) (16.0.6)\n",
      "Requirement already satisfied: lxml==4.9.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 46)) (4.9.3)\n",
      "Requirement already satisfied: Markdown==3.4.4 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 47)) (3.4.4)\n",
      "Requirement already satisfied: MarkupSafe==2.1.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 48)) (2.1.3)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 49)) (0.2.0)\n",
      "Requirement already satisfied: mpmath==1.3.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 50)) (1.3.0)\n",
      "Requirement already satisfied: msgpack==1.0.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 51)) (1.0.5)\n",
      "Requirement already satisfied: mygene==3.2.2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 52)) (3.2.2)\n",
      "Requirement already satisfied: networkx==3.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 53)) (3.1)\n",
      "Requirement already satisfied: numpy==1.23.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 54)) (1.23.5)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 55)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 56)) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 57)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 58)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 59)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 60)) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 61)) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 62)) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 63)) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 64)) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 65)) (11.7.91)\n",
      "Requirement already satisfied: oauthlib==3.2.2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 66)) (3.2.2)\n",
      "Requirement already satisfied: opt-einsum==3.3.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 67)) (3.3.0)\n",
      "Requirement already satisfied: packaging==23.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 68)) (23.1)\n",
      "Requirement already satisfied: pandas==2.0.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 69)) (2.0.3)\n",
      "Requirement already satisfied: Pillow==10.0.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 70)) (10.0.0)\n",
      "Requirement already satisfied: platformdirs==3.10.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 71)) (3.10.0)\n",
      "Requirement already satisfied: pooch==1.7.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 72)) (1.7.0)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.39 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 73)) (3.0.39)\n",
      "Requirement already satisfied: protein-bert==1.0.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 74)) (1.0.1)\n",
      "Requirement already satisfied: protobuf==4.24.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 75)) (4.24.3)\n",
      "Requirement already satisfied: psutil==5.9.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 76)) (5.9.5)\n",
      "Requirement already satisfied: pyasn1==0.5.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 77)) (0.5.0)\n",
      "Requirement already satisfied: pyasn1-modules==0.3.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 78)) (0.3.0)\n",
      "Requirement already satisfied: pyfaidx==0.7.2.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 79)) (0.7.2.1)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 80)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2023.3.post1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 81)) (2023.3.post1)\n",
      "Requirement already satisfied: PyYAML==6.0.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 82)) (6.0.1)\n",
      "Requirement already satisfied: redis==4.6.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 83)) (4.6.0)\n",
      "Requirement already satisfied: regex==2023.8.8 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 84)) (2023.8.8)\n",
      "Requirement already satisfied: requests==2.31.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 85)) (2.31.0)\n",
      "Requirement already satisfied: requests-oauthlib==1.3.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 86)) (1.3.1)\n",
      "Requirement already satisfied: rsa==4.9 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 87)) (4.9)\n",
      "Requirement already satisfied: safetensors==0.3.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 88)) (0.3.3)\n",
      "Requirement already satisfied: scipy==1.10.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 89)) (1.10.1)\n",
      "Requirement already satisfied: seaborn in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 90)) (0.13.0)\n",
      "Requirement already satisfied: sentencepiece==0.1.99 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 91)) (0.1.99)\n",
      "Requirement already satisfied: six==1.16.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 92)) (1.16.0)\n",
      "Requirement already satisfied: sympy==1.12 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 93)) (1.12)\n",
      "Requirement already satisfied: tensorboard==2.12.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 94)) (2.12.3)\n",
      "Requirement already satisfied: tensorboard-data-server==0.7.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 95)) (0.7.1)\n",
      "Requirement already satisfied: tensorflow==2.12.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 96)) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-addons==0.21.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 97)) (0.21.0)\n",
      "Requirement already satisfied: tensorflow-estimator==2.12.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 98)) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.34.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 99)) (0.34.0)\n",
      "Requirement already satisfied: termcolor==2.3.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 100)) (2.3.0)\n",
      "Requirement already satisfied: tokenizers==0.13.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 101)) (0.13.3)\n",
      "Requirement already satisfied: torch==2.0.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 102)) (2.0.1)\n",
      "Requirement already satisfied: torchaudio==2.0.2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 103)) (2.0.2)\n",
      "Requirement already satisfied: torchvision==0.15.2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 104)) (0.15.2)\n",
      "Requirement already satisfied: tqdm==4.66.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 105)) (4.66.1)\n",
      "Requirement already satisfied: transformers==4.33.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 106)) (4.33.1)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 107)) (2.0.0)\n",
      "Requirement already satisfied: typeguard==2.13.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 108)) (2.13.3)\n",
      "Requirement already satisfied: typing_extensions==4.7.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 109)) (4.7.1)\n",
      "Requirement already satisfied: tzdata==2023.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 110)) (2023.3)\n",
      "Requirement already satisfied: urllib3==1.26.16 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 111)) (1.26.16)\n",
      "Requirement already satisfied: vine==5.0.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 112)) (5.0.0)\n",
      "Requirement already satisfied: wcwidth==0.2.6 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 113)) (0.2.6)\n",
      "Requirement already satisfied: Werkzeug==2.3.7 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 114)) (2.3.7)\n",
      "Requirement already satisfied: wrapt==1.14.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 115)) (1.14.1)\n",
      "Requirement already satisfied: WTForms==3.0.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from -r requirements.txt (line 116)) (3.0.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from astunparse==1.6.3->-r requirements.txt (line 4)) (0.41.1)\n",
      "Requirement already satisfied: backports.zoneinfo>=0.2.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from celery==5.3.4->-r requirements.txt (line 14)) (0.2.1)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from Flask==2.3.3->-r requirements.txt (line 24)) (6.8.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->-r requirements.txt (line 55)) (68.0.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from seaborn->-r requirements.txt (line 90)) (3.7.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from importlib-metadata>=3.6.0->Flask==2.3.3->-r requirements.txt (line 24)) (3.16.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn->-r requirements.txt (line 90)) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn->-r requirements.txt (line 90)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn->-r requirements.txt (line 90)) (4.42.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn->-r requirements.txt (line 90)) (1.4.4)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn->-r requirements.txt (line 90)) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn->-r requirements.txt (line 90)) (6.0.1)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install requirements from requirements file\n",
    "%pip install -r requirements.txt\n",
    "\n",
    "# Alternative: Install requirements directly\n",
    "# %pip install blosum\n",
    "# %pip install Bio\n",
    "# %pip install torch torchvision torchaudio transformers sentencepiece accelerate --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "# %pip install protein-bert\n",
    "# %pip install biopython biotite\n",
    "# %pip install fair-esm\n",
    "# %pip install scipy\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o3BStrXj6JQ2",
    "outputId": "af5c2e52-88a3-485f-f382-e704171b2969"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "import blosum as bl\n",
    "from Bio import SeqIO\n",
    "import random\n",
    "from scipy import stats\n",
    "import torch\n",
    "import esm\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import statistics\n",
    "import time\n",
    "from zipfile import ZipFile\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from models import get_model\n",
    "from embeddings import get_fasta_embeddings, get_pair_embeddings, load_fasta\n",
    "\n",
    "# Retrieve the device (CPU or GPU)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device: {}\".format(device))\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Available models\n",
    "MODELS_LIST = [\"ProtT5\", \"ProtBert\", \"ProtAlbert\", \"ProtXLNet\", \"ESM1b\", \"ESM2\"]\n",
    "\n",
    "# Available alignment types\n",
    "ALIGNMENT_TYPES = [\"Global-regular\" , \"Global-end-gap-free\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qs6JenWnHYHo"
   },
   "source": [
    "# Alignment Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTFhk7slsYA1"
   },
   "source": [
    "## Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "r5iNmd9o6Q3V"
   },
   "outputs": [],
   "source": [
    "def affine_global_dp(seq_1, seq_2, g_open, g_ext,\n",
    "                     scoring=\"ProtT5\", Model=None, Model_tokenizer=None):\n",
    "    # initialize the matrix\n",
    "    m = len(seq_1);\n",
    "    n = len(seq_2)\n",
    "    M = np.zeros([m + 1, n + 1])\n",
    "    M[0, 1:] = g_open + g_ext * np.arange(0, n, 1)\n",
    "    M[1:, 0] = g_open + g_ext * np.arange(0, m, 1)\n",
    "    L = np.copy(M);\n",
    "    U = np.copy(M)\n",
    "    L[1:, 0] = L[1:, 0] + g_open;\n",
    "    U[0, 1:] = U[0, 1:] + g_open  # avoiding Gotoh's error\n",
    "\n",
    "    # fill up\n",
    "    tracer = np.zeros([np.shape(M)[0], np.shape(M)[1], 7])\n",
    "  \n",
    "    # Get embeddings\n",
    "    emb1, emb2 = get_pair_embeddings(seq_1, seq_2, Model, Model_tokenizer, scoring)\n",
    "    cos = torch.nn.CosineSimilarity(dim=0)\n",
    "\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            l_arr = np.array([M[i, j - 1] + g_open, L[i, j - 1] + g_ext])\n",
    "            L[i, j] = np.max(l_arr)\n",
    "            l_where = l_arr == np.max(l_arr)\n",
    "\n",
    "            u_arr = np.array([M[i - 1, j] + g_open, U[i - 1, j] + g_ext])\n",
    "            U[i, j] = np.max(u_arr)\n",
    "            u_where = u_arr == np.max(u_arr)\n",
    "\n",
    "            if scoring in MODELS_LIST:\n",
    "                sim = cos(torch.tensor(emb1[i - 1], dtype=torch.float32)\n",
    "                          , torch.tensor(emb2[j - 1], dtype=torch.float32)).item()\n",
    "\n",
    "                m_arr = np.array([M[i - 1, j - 1] + sim, U[i, j], L[i, j]])\n",
    "\n",
    "            M[i, j] = np.max(m_arr)\n",
    "            m_where = m_arr == np.max(m_arr)\n",
    "\n",
    "            idx = np.hstack([m_where, u_where, l_where])\n",
    "            tracer[i, j, idx] = 1\n",
    "\n",
    "    # traceback\n",
    "\n",
    "    alignment = []\n",
    "    alignment.append(traceback_g(tracer, seq_1, seq_2, affine= True, roadmap=0))\n",
    "\n",
    "    alignment = list(set(map(tuple, alignment)))\n",
    "\n",
    "    return M, L, U, tracer, alignment\n",
    "\n",
    "\n",
    "def traceback_g(tracer, seq_1, seq_2, mat=None, affine=False, roadmap=0):\n",
    "    # get sequence lengths\n",
    "    m = len(seq_1);\n",
    "    n = len(seq_2)\n",
    "\n",
    "    # convert to numpy arrays\n",
    "    x = np.array(list(seq_1), dtype='object')\n",
    "    y = np.array(list(seq_2), dtype='object')\n",
    "\n",
    "    # set start location\n",
    "    st = [m + 1, n + 1]\n",
    "\n",
    "    st_lv = 0  # start in midgard\n",
    "\n",
    "    while ((st[0] > 1) & (st[1] > 1)):\n",
    "\n",
    "        B = np.zeros([2, 2])  # define 2x2 box which specifies which way to move\n",
    "\n",
    "        if affine is True:\n",
    "            Tr = np.zeros([7])  # define a 7x1 Tr array (will store arrows at each step)\n",
    "        else:\n",
    "            Tr = np.zeros([3])  # define a 3x1 Tr array (will store arrows at each step)\n",
    "\n",
    "        if affine is False:\n",
    "            Tr[0] = np.copy(tracer[st[0] - 1, st[1] - 1, 0])\n",
    "            Tr[1] = np.copy(tracer[st[0] - 1, st[1] - 1, 1])\n",
    "            Tr[2] = np.copy(tracer[st[0] - 1, st[1] - 1, 2])\n",
    "\n",
    "        else:\n",
    "            # tracer\n",
    "            Tr[0] = np.copy(tracer[st[0] - 1, st[1] - 1, 0])\n",
    "            Tr[1] = np.copy(tracer[st[0] - 1, st[1] - 1, 1])\n",
    "            Tr[2] = np.copy(tracer[st[0] - 1, st[1] - 1, 2])\n",
    "            Tr[3] = np.copy(tracer[st[0] - 1, st[1] - 1, 3])\n",
    "            Tr[4] = np.copy(tracer[st[0] - 1, st[1] - 1, 4])\n",
    "            Tr[5] = np.copy(tracer[st[0] - 1, st[1] - 1, 5])\n",
    "            Tr[6] = np.copy(tracer[st[0] - 1, st[1] - 1, 6])\n",
    "\n",
    "        # bifurcations\n",
    "        if affine is True:\n",
    "            levels = [[2, 0, 1], [4, 3], [6, 5]]\n",
    "        else:\n",
    "            levels = [[2, 0, 1]]\n",
    "        for l in levels:\n",
    "            if np.sum(Tr[l]) > 1:\n",
    "                choose = np.where(Tr[l] == 1)[0]\n",
    "                Tr[l] = 0\n",
    "                if roadmap == 0:\n",
    "                    r = np.random.choice(choose, 1)[0]  # random turning\n",
    "                elif roadmap == 1:\n",
    "                    r = choose[-1]  # highroad\n",
    "                elif roadmap == 2:\n",
    "                    r = choose[0]  # lowroad\n",
    "                else:\n",
    "                    raise Exception(\"roadmap only accepts 0: random turning, 1: highroad, 2: lowroad\")\n",
    "                Tr[l[r]] = 1\n",
    "\n",
    "        # level up-down\n",
    "        if ((Tr[0] == 1) & (st_lv == 0)):  # diagonal\n",
    "            B[0, 0] = 1\n",
    "\n",
    "        if ((Tr[1] == 1) & (st_lv == 0)):\n",
    "            if affine is True:\n",
    "                st_lv = 1  # level up\n",
    "            else:\n",
    "                B[0, 1] = 1\n",
    "\n",
    "        if ((Tr[2] == 1) & (st_lv == 0)):\n",
    "            if affine is True:\n",
    "                st_lv = 2  # level down\n",
    "            else:\n",
    "                B[1, 0] = 1\n",
    "\n",
    "        # affine gaps allow for level shifts\n",
    "        if affine is True:\n",
    "            if ((Tr[4] == 1) & (st_lv == 1)):  # move up\n",
    "                B[0, 1] = 1\n",
    "\n",
    "            if ((Tr[3] == 1) & (st_lv == 1)):  # move up back to main\n",
    "                st_lv = 0\n",
    "                B[0, 1] = 1\n",
    "\n",
    "            if ((Tr[6] == 1) & (st_lv == 2)):  # move left\n",
    "                B[1, 0] = 1\n",
    "\n",
    "            if ((Tr[5] == 1) & (st_lv == 2)):  # move left back to main\n",
    "                st_lv = 0\n",
    "                B[1, 0] = 1\n",
    "\n",
    "        # movements\n",
    "        if B[0, 1] == 1:  # upward\n",
    "            y = np.insert(y, st[1] - 1, '-')  # add a gap\n",
    "            st[0] = st[0] - 1\n",
    "\n",
    "        if B[1, 0] == 1:  # leftward\n",
    "            x = np.insert(x, st[0] - 1, '-')  # add a gap\n",
    "            st[1] = st[1] - 1\n",
    "\n",
    "        if B[0, 0] == 1:  # diagonal\n",
    "            st[1] = st[1] - 1\n",
    "            st[0] = st[0] - 1\n",
    "\n",
    "    # some end gaps are left when you hit the upper/lower end of the matrix or a 0\n",
    "    end_size = (np.size(x) - np.size(y))  # how many gaps and for which sequence\n",
    "    end_gap = (['-'] * abs(end_size))\n",
    "    if end_size > 0:\n",
    "        y = np.insert(y, 0, end_gap)\n",
    "    elif end_size < 0:\n",
    "        x = np.insert(x, 0, end_gap)\n",
    "\n",
    "    # check no overlapping gaps\n",
    "    x = np.where(((x == '-') & (y == '-')), None, x)\n",
    "    y = np.where((x == None), '', y)\n",
    "    x = np.where((x == None), '', x)\n",
    "\n",
    "    return np.sum(x), np.sum(y)\n",
    "\n",
    "\n",
    "def traceback_iterator_g(tracer, seq_1, seq_2,\n",
    "                         affine=False):\n",
    "    alignment = []\n",
    "    alignment.append(traceback_g(tracer, seq_1, seq_2, affine=affine, roadmap=0))\n",
    "\n",
    "    return list(set(map(tuple, alignment)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiNZQ2SQJM54"
   },
   "source": [
    "## Prefix/Suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MqzYFa7dJTY9"
   },
   "outputs": [],
   "source": [
    "def affine_semi_global_dp(seq_1, seq_2, g_open, g_ext,\n",
    "                          high_low=False, scoring=\"ProtT5\", Model=None, Model_tokenizer=None):\n",
    "    # Initialize the matrix\n",
    "    m = len(seq_1);\n",
    "    n = len(seq_2)\n",
    "    M = np.zeros([m + 1, n + 1])\n",
    "    M[0, 1:] = 0\n",
    "    M[1:, 0] = 0\n",
    "    L = np.copy(M);\n",
    "    U = np.copy(M)\n",
    "    L[1:, 0] = 0;\n",
    "    U[0, 1:] = 0\n",
    "\n",
    "    # Fill up\n",
    "    tracer = np.zeros([np.shape(M)[0], np.shape(M)[1], 7])\n",
    "\n",
    "    # Get embeddings\n",
    "    emb1, emb2 = get_pair_embeddings(seq_1, seq_2, Model, Model_tokenizer, scoring)\n",
    "    cos = torch.nn.CosineSimilarity(dim=0)\n",
    "\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            l_arr = np.array([M[i, j - 1] + g_open, L[i, j - 1] + g_ext])\n",
    "            L[i, j] = np.max(l_arr)\n",
    "            l_where = l_arr == np.max(l_arr)\n",
    "\n",
    "            u_arr = np.array([M[i - 1, j] + g_open, U[i - 1, j] + g_ext])\n",
    "            U[i, j] = np.max(u_arr)\n",
    "            u_where = u_arr == np.max(u_arr)\n",
    "\n",
    "            if scoring in MODELS_LIST:\n",
    "                sim = cos(torch.tensor(emb1[i - 1], dtype=torch.float32)\n",
    "                          , torch.tensor(emb2[j - 1], dtype=torch.float32)).item()\n",
    "\n",
    "                m_arr = np.array([M[i - 1, j - 1] + sim, U[i, j], L[i, j]])\n",
    "\n",
    "            M[i, j] = np.max(m_arr)\n",
    "            m_where = m_arr == np.max(m_arr)\n",
    "\n",
    "            idx = np.hstack([m_where, u_where, l_where])\n",
    "            tracer[i, j, idx] = 1\n",
    "\n",
    "\n",
    "    alignment = []\n",
    "    alignment.append(traceback_sg(tracer, seq_1, seq_2, mat=M, affine=True,\n",
    "                                  local= True, roadmap=0))\n",
    "    alignment = list(set(map(tuple, alignment)))\n",
    "\n",
    "    return M, L, U, tracer, alignment\n",
    "\n",
    "\n",
    "def traceback_sg(tracer, seq_1, seq_2, mat=None, local=False, affine=False, roadmap=0):\n",
    "\n",
    "    m = len(seq_1);\n",
    "    n = len(seq_2)\n",
    "\n",
    "    x = np.array(list(seq_1), dtype='object')\n",
    "    y = np.array(list(seq_2), dtype='object')\n",
    "\n",
    "    # set start location\n",
    "    if roadmap == 0:\n",
    "        r = np.random.choice(range(np.size(np.where(mat == np.max(mat))[0])), 1)[0]  # random maxima\n",
    "    elif roadmap == 1:\n",
    "        r = -1\n",
    "    elif roadmap == 2:\n",
    "        r = 0\n",
    "\n",
    "    st = [(np.where(mat == np.max(mat))[0][r]) + 1, (np.where(mat == np.max(mat))[1][r]) + 1]\n",
    "\n",
    "    # set starting gaps based on the start location\n",
    "    start_size = ((m - st[0]) - (n - st[1]))  # how many gaps and for which sequence\n",
    "    start_gap = (['-'] * abs(start_size))\n",
    "    if start_size > 0:\n",
    "        y = np.append(y, start_gap)\n",
    "    elif start_size < 0:\n",
    "        x = np.append(x, start_gap)\n",
    "\n",
    "    st_lv = 0  # start in midgard\n",
    "\n",
    "    while ((st[0] > 1) & (st[1] > 1)):\n",
    "\n",
    "        B = np.zeros([2, 2])  # define 2x2 box which specifies which way to move\n",
    "\n",
    "        if affine is True:\n",
    "            Tr = np.zeros([7])  # define a 7x1 Tr array (will store arrows at each step)\n",
    "        else:\n",
    "            Tr = np.zeros([3])  # define a 3x1 Tr array (will store arrows at each step)\n",
    "\n",
    "\n",
    "        if affine is False:\n",
    "            Tr[0] = np.copy(tracer[st[0] - 1, st[1] - 1, 0])\n",
    "            Tr[1] = np.copy(tracer[st[0] - 1, st[1] - 1, 1])\n",
    "            Tr[2] = np.copy(tracer[st[0] - 1, st[1] - 1, 2])\n",
    "\n",
    "        else:\n",
    "            # tracer\n",
    "            Tr[0] = np.copy(tracer[st[0] - 1, st[1] - 1, 0])\n",
    "            Tr[1] = np.copy(tracer[st[0] - 1, st[1] - 1, 1])\n",
    "            Tr[2] = np.copy(tracer[st[0] - 1, st[1] - 1, 2])\n",
    "            Tr[3] = np.copy(tracer[st[0] - 1, st[1] - 1, 3])\n",
    "            Tr[4] = np.copy(tracer[st[0] - 1, st[1] - 1, 4])\n",
    "            Tr[5] = np.copy(tracer[st[0] - 1, st[1] - 1, 5])\n",
    "            Tr[6] = np.copy(tracer[st[0] - 1, st[1] - 1, 6])\n",
    "\n",
    "        # bifurcations\n",
    "        if affine is True:\n",
    "            levels = [[2, 0, 1], [4, 3], [6, 5]]\n",
    "        else:\n",
    "            levels = [[2, 0, 1]]\n",
    "        for l in levels:\n",
    "            if np.sum(Tr[l]) > 1:\n",
    "                choose = np.where(Tr[l] == 1)[0]\n",
    "                Tr[l] = 0\n",
    "                if roadmap == 0:\n",
    "                    r = np.random.choice(choose, 1)[0]  # random turning\n",
    "                elif roadmap == 1:\n",
    "                    r = choose[-1]  # highroad\n",
    "                elif roadmap == 2:\n",
    "                    r = choose[0]  # lowroad\n",
    "                else:\n",
    "                    raise Exception(\"roadmap only accepts 0: random turning, 1: highroad, 2: lowroad\")\n",
    "                Tr[l[r]] = 1\n",
    "\n",
    "        # level up-down\n",
    "        if ((Tr[0] == 1) & (st_lv == 0)):  # diagonal\n",
    "            B[0, 0] = 1\n",
    "\n",
    "        if ((Tr[1] == 1) & (st_lv == 0)):\n",
    "            if affine is True:\n",
    "                st_lv = 1  # level up\n",
    "            else:\n",
    "                B[0, 1] = 1\n",
    "\n",
    "        if ((Tr[2] == 1) & (st_lv == 0)):\n",
    "            if affine is True:\n",
    "                st_lv = 2  # level down\n",
    "            else:\n",
    "                B[1, 0] = 1\n",
    "\n",
    "        # affine gaps allow for level shifts\n",
    "        if affine is True:\n",
    "            if ((Tr[4] == 1) & (st_lv == 1)):  # move up\n",
    "                B[0, 1] = 1\n",
    "\n",
    "            if ((Tr[3] == 1) & (st_lv == 1)):  # move up back to main\n",
    "                st_lv = 0\n",
    "                B[0, 1] = 1\n",
    "\n",
    "            if ((Tr[6] == 1) & (st_lv == 2)):  # move left\n",
    "                B[1, 0] = 1\n",
    "\n",
    "            if ((Tr[5] == 1) & (st_lv == 2)):  # move left back to main\n",
    "                st_lv = 0\n",
    "                B[1, 0] = 1\n",
    "\n",
    "        if local is True:\n",
    "            if (mat[st[0] - 1, st[1] - 1] == 0):\n",
    "                break\n",
    "\n",
    "        # movements\n",
    "        if B[0, 1] == 1:  # upward\n",
    "            y = np.insert(y, st[1] - 1, '-')  # add a gap\n",
    "            st[0] = st[0] - 1\n",
    "\n",
    "        if B[1, 0] == 1:  # leftward\n",
    "            x = np.insert(x, st[0] - 1, '-')  # add a gap\n",
    "            st[1] = st[1] - 1\n",
    "\n",
    "        if B[0, 0] == 1:  # diagonal\n",
    "            st[1] = st[1] - 1\n",
    "            st[0] = st[0] - 1\n",
    "\n",
    "    # some end gaps are left when you hit the upper/lower end of the matrix or a 0\n",
    "    end_size = (np.size(x) - np.size(y))  # how many gaps and for which sequence\n",
    "    end_gap = (['-'] * abs(end_size))\n",
    "    if end_size > 0:\n",
    "        y = np.insert(y, 0, end_gap)\n",
    "    elif end_size < 0:\n",
    "        x = np.insert(x, 0, end_gap)\n",
    "\n",
    "    # check no overlapping gaps\n",
    "    x = np.where(((x == '-') & (y == '-')), None, x)\n",
    "    y = np.where((x == None), '', y)\n",
    "    x = np.where((x == None), '', x)\n",
    "\n",
    "    return np.sum(x), np.sum(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IMkkTPWsaF0"
   },
   "source": [
    "# Aux Funx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LBNOVyaN7ZT3"
   },
   "outputs": [],
   "source": [
    "def just_seqs(seqs):\n",
    "    \"\"\" Extracts the sequence from a list of (name, sequence) tuples \"\"\"\n",
    "    final_seqs = []\n",
    "    for seq in seqs:\n",
    "        final_seqs.append(seq[1])\n",
    "\n",
    "    return final_seqs\n",
    "\n",
    "def aligned_to_indexed(seqs):\n",
    "  \"\"\" Removes dashes (-) in a sequence and creates positions array for non-dash residues \"\"\"\n",
    "  no_dash = []\n",
    "  positions = []\n",
    "  for seq in seqs:\n",
    "    no_dash.append(seq.replace(\"-\" , \"\"))\n",
    "    pos = []\n",
    "    for i , char in enumerate(seq):\n",
    "      if char != \"-\":\n",
    "        pos.append(i)\n",
    "    positions.append(pos)\n",
    "\n",
    "  return no_dash, positions\n",
    "\n",
    "def length_matcher(x , y , place = \"\"):\n",
    "  \"\"\" Matches the length between x and y with spaces if necessary \"\"\"\n",
    "  length = 5\n",
    "\n",
    "  if len(x) < length:\n",
    "    spaces = abs(len(x) - length)\n",
    "\n",
    "    if place == \"Back\":\n",
    "      x = \" \" * spaces + x\n",
    "    if place == \"Front\":\n",
    "      x = x + \" \" * spaces\n",
    "\n",
    "  if len(y) < length:\n",
    "    spaces = abs(len(y) - length)\n",
    "\n",
    "    if place == \"Back\":\n",
    "      y = \" \" * spaces + y\n",
    "    if place == \"Front\":\n",
    "      y = y + \" \" * spaces\n",
    "\n",
    "  return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "achF78kUscys"
   },
   "source": [
    "# Alignment Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DawofHCVAdVo"
   },
   "outputs": [],
   "source": [
    "def get_alignments(prot1, prot2, gap_penalty = 0, gap_extension_penalty = 0 ,\n",
    "                   scoring = \"ProtT5\" , alignment_type = \"Global-regular\" , Model = \"\" , Model_Tokenizer = \"\"):\n",
    "    \"\"\" Gets the alignments between two sequences \"\"\"\n",
    "    \n",
    "    if alignment_type == \"Global-regular\":\n",
    "      M, L, U , tracer , alignment = affine_global_dp(prot1, prot2, gap_penalty, gap_extension_penalty\n",
    "                                                    ,scoring = scoring , Model = Model, Model_tokenizer = Model_Tokenizer)\n",
    "      max_score = np.max(M)\n",
    "\n",
    "    if alignment_type == \"Global-end-gap-free\" or alignment_type == \"End-Gap-Free\":\n",
    "      M, L, U , tracer , alignment = affine_semi_global_dp(prot1, prot2, gap_penalty, gap_extension_penalty\n",
    "                                                    ,scoring = scoring , Model = Model, Model_tokenizer = Model_Tokenizer)\n",
    "      max_score = max(M[-1,-1],L[-1,-1],U[-1,-1])\n",
    "\n",
    "    # Return (reference alignment, query alignment, alignment score)\n",
    "    aligned1 = alignment[0][0]\n",
    "    aligned2 = alignment[0][1]\n",
    "\n",
    "    return aligned1, aligned2, max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5Hfj5rAk4_cg"
   },
   "outputs": [],
   "source": [
    "def get_visualization(prot1, prot2 , score , Type = \"\" , Model = \"\" , Model_Tokenizer = \"\"):\n",
    "  MODELS_LIST = [\"ProtT5\" , \"ProtBert\" , \"ProtAlbert\" , \"ProtXLNet\" , \"ESM1b\" , \"ESM2\"]\n",
    "  cos = torch.nn.CosineSimilarity(dim=0)\n",
    "\n",
    "  seqs = [prot1 , prot2]\n",
    "  no_dash , positions = aligned_to_indexed(seqs)\n",
    "  model = Model\n",
    "  tokenizer = Model_Tokenizer\n",
    "\n",
    "  # Get embeddings\n",
    "  p1_emb, p2_emb = get_pair_embeddings(no_dash[0], no_dash[1], Model, Model_Tokenizer, Type)\n",
    "\n",
    "  p1_revived = \"\"\n",
    "  p2_revived = \"\"\n",
    "  aligned_info = \"\"\n",
    "\n",
    "  for i in range(len(prot1)):\n",
    "\n",
    "    if i in positions[0]:\n",
    "      p1_revived += prot1[i]\n",
    "    else:\n",
    "      p1_revived += \"-\"\n",
    "\n",
    "    if i in positions[1]:\n",
    "      p2_revived += prot2[i]\n",
    "    else:\n",
    "      p2_revived += \"-\"\n",
    "\n",
    "\n",
    "    if p1_revived[-1] == p2_revived[-1]:\n",
    "      aligned_info += p1_revived[-1]\n",
    "\n",
    "    elif p1_revived[-1] == \"-\" or p2_revived[-1] == \"-\":\n",
    "      aligned_info += \" \"\n",
    "\n",
    "    elif p1_revived[-1] != p2_revived[-1]:\n",
    "\n",
    "      if Type in MODELS_LIST:\n",
    "        sim = cos(torch.tensor(p1_emb[0][positions[0].index(i)] , dtype = torch.float32) ,\n",
    "                  torch.tensor(p2_emb[0][positions[1].index(i)] , dtype = torch.float32)).item()\n",
    "\n",
    "        aligned_info += \" \"\n",
    "\n",
    "  del model\n",
    "  del tokenizer\n",
    "\n",
    "  return p1_revived , aligned_info, p2_revived, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7nB5_MdnBO5"
   },
   "source": [
    "# Alignment For 2 Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dyAQgxCFn99V"
   },
   "outputs": [],
   "source": [
    "def alignment_file_TXT(saving_add, seqs_path, scoring, alignment_type,\n",
    "                      gap_penalty, gap_extension_penalty):\n",
    "  \"\"\" Creates and outputs the alignmment file between two sequences \"\"\"\n",
    "  print(f\"Device: {device}\")\n",
    "\n",
    "  # Get selected model\n",
    "  Model , Model_Tokenizer = get_model(scoring)\n",
    "\n",
    "  # Load sequences from FASTA file\n",
    "  seqs = load_fasta(seqs_path)\n",
    "\n",
    "  # Get protein sequences\n",
    "  prot1 = seqs[0][1]\n",
    "  prot2 = seqs[1][1]\n",
    "\n",
    "  # Get names of protein sequences\n",
    "  name1 = seqs[0][0]\n",
    "  name2 = seqs[1][0]\n",
    "\n",
    "  # Get alignments and visualization\n",
    "  reference_al, query_al, al_score = get_alignments(prot1, prot2, gap_penalty = gap_penalty,\n",
    "                    gap_extension_penalty = gap_extension_penalty ,\n",
    "                                              scoring = scoring , alignment_type = alignment_type,\n",
    "                                              Model = Model , Model_Tokenizer = Model_Tokenizer)\n",
    "\n",
    "  p1_al , aligned_info , p2_al , al_score = get_visualization(reference_al , query_al, al_score , Type = scoring,\n",
    "                                                              Model = Model, Model_Tokenizer = Model_Tokenizer)\n",
    "\n",
    "  if not os.path.exists(saving_add):\n",
    "   os.makedirs(saving_add)\n",
    "\n",
    "  file_name = saving_add + seqs_path.split(\"/\")[-1].split(\".\")[-2] + \"_\" + scoring + \"_\" + alignment_type + \"_\"\n",
    "  file_name += str(gap_penalty) + \"_\" + str(gap_extension_penalty) + \"_\"+ \"Alignment\" + \".txt\"\n",
    "  f = open(file_name, \"w\")\n",
    "\n",
    "  # Write Sequence 1 Information\n",
    "  f.write(\"Seq 1 \\n\")\n",
    "  f.write(\">\" + name1 + \"\\n\")\n",
    "  f.write(reference_al.replace(\"-\" , \"\") + \"\\n\")\n",
    "    \n",
    "  # Write Sequence 2 Information\n",
    "  f.write(\"Seq 2 \\n\")\n",
    "  f.write(\">\" + name2 + \"\\n\")\n",
    "  f.write(query_al.replace(\"-\" , \"\") + \"\\n\\n\")\n",
    "    \n",
    "  # Write Alignment Information\n",
    "  f.write(\"Alignment Type : \" + alignment_type + \"\\n\\n\")\n",
    "  f.write(\"Opening Gap Penalty : \" + str(gap_penalty) + \"\\n\")\n",
    "  f.write(\"Extension Gap Penalty : \" + str(gap_extension_penalty) + \"\\n\")\n",
    "  f.write(\"Scoring System : \" + scoring + \"\\n\")\n",
    "  f.write(\"Score : \"  + str(al_score) + \"\\n\\n\")\n",
    "\n",
    "  p1_pos = 1\n",
    "  p2_pos = 1\n",
    "  aligned_gaps = \"\"\n",
    "\n",
    "  for j in range(int(len(p1_al) / 60) + 1):\n",
    "    p1_posix = p1_al[j * 60: (j + 1) * 60]\n",
    "    p2_posix = p2_al[j * 60: (j + 1) * 60]\n",
    "    p1_back_str, p2_back_str = length_matcher(str(p1_pos) , str(p2_pos) , place = \"Front\")\n",
    "\n",
    "    for k in range(len(p1_posix)):\n",
    "      if p1_posix[k] != \"-\":\n",
    "        p1_pos += 1\n",
    "      if p2_posix[k] != \"-\":\n",
    "        p2_pos += 1\n",
    "\n",
    "    p1_end_str, p2_end_str = length_matcher(str(p1_pos - 1) , str(p2_pos - 1) , place = \"Back\")\n",
    "    aligned_gaps = \" \" * len(p1_back_str)\n",
    "\n",
    "    f.write(\"Seq 1 : \" + p1_back_str + \" \" + p1_al[j * 60: (j + 1) * 60] + \" \" + p1_end_str + \"\\n\")\n",
    "    f.write(\"        \"  +  aligned_gaps + \" \" + aligned_info[j * 60: (j + 1) * 60] + \"\\n\")\n",
    "    f.write(\"Seq 2 : \"  + p2_back_str + \" \" + p2_al[j * 60: (j + 1) * 60] + \" \" + p2_end_str + \"\\n\\n\")\n",
    "\n",
    "  print(\"Alignment Computation is Done!\")\n",
    "  del Model\n",
    "  del Model_Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OaiQRMPjkWbg"
   },
   "outputs": [],
   "source": [
    "def user_guide(MODELS_LIST):\n",
    "  \"\"\" User guide for the E-score program \"\"\"\n",
    "  print(\"Parameters & Descriptions:\")\n",
    "  print(\"  saving_add:\".ljust(25) + \"Output directory path\")\n",
    "  print(\"  seqs_path:\".ljust(25) + \"FASTA file with two protein sequences\")\n",
    "    \n",
    "  print(\"  scoring_type:\".ljust(25) + \"Model for embedding production (\", end = \"\")\n",
    "  for model_name in MODELS_LIST[:-1] : print(model_name + \", \" , end = \"\")\n",
    "  print(MODELS_LIST[-1] + \")\")\n",
    "\n",
    "  print(\"  alignment_type:\".ljust(25) + \"Global-regular or Global-end-gap-free\")\n",
    "  print(\"  gap_penalty:\".ljust(25) + \"Default: -1.0 | Recommended Values: -4.0, -3.0, -2.0, -1.5, -1.0, -0.5\")\n",
    "  print(\"  gap_extension_penalty:\".ljust(25) + \"Default: -0.2 | Recommended Values: -1.0, -0.8, -0.5, -0.3, -0.2, -0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVRUmBYkG4M3"
   },
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Tyat_ydz5f4",
    "outputId": "d0b958ab-ed49-469e-ae38-44c0c744c10a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters & Descriptions:\n",
      "  saving_add:            Output directory path\n",
      "  seqs_path:             FASTA file with two protein sequences\n",
      "  scoring_type:          Model for embedding production (ProtT5, ProtBert, ProtAlbert, ProtXLNet, ESM1b, ESM2)\n",
      "  alignment_type:        Global-regular or Global-end-gap-free\n",
      "  gap_penalty:           Default: -1.0 | Recommended Values: -4.0, -3.0, -2.0, -1.5, -1.0, -0.5\n",
      "  gap_extension_penalty: Default: -0.2 | Recommended Values: -1.0, -0.8, -0.5, -0.3, -0.2, -0.1\n"
     ]
    }
   ],
   "source": [
    "user_guide(MODELS_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "glng92tRG5ZZ",
    "outputId": "f876fd26-98b1-4520-c2ed-337e2758f0ff",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Initializing ProtT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating T5 Embeddings\n",
      "Generating T5 Embeddings\n",
      "Alignment Computation is Done!\n"
     ]
    }
   ],
   "source": [
    "# Defining Parameters\n",
    "saving_add =  \"./content/\"\n",
    "seqs_path = \"../data/Test2.fasta\"\n",
    "scoring = MODELS_LIST[0]\n",
    "alignment_type = ALIGNMENT_TYPES[0]\n",
    "gap_penalty = -1\n",
    "gap_extension_penalty = -0.2\n",
    "\n",
    "# Generating Alignment File\n",
    "alignment_file_TXT(saving_add = saving_add , seqs_path = seqs_path, scoring = scoring, alignment_type = alignment_type,\n",
    "                      gap_penalty = gap_penalty, gap_extension_penalty = gap_extension_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_embeddings(seqs_path, scoring):\n",
    "    \"\"\" Analyze the embeddings between two sequences \"\"\"\n",
    "    embeddings = get_fasta_embeddings(seqs_path, scoring)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "analyze_embeddings() takes 2 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Riley\\Documents\\repos\\e-score\\src\\e-score.ipynb Cell 24\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Riley/Documents/repos/e-score/src/e-score.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m alignment_type \u001b[39m=\u001b[39m ALIGNMENT_TYPES[\u001b[39m0\u001b[39m] \u001b[39m# Global\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Riley/Documents/repos/e-score/src/e-score.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Analysis\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Riley/Documents/repos/e-score/src/e-score.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(analyze_embeddings(saving_add, seqs_path, scoring, alignment_type))\n",
      "\u001b[1;31mTypeError\u001b[0m: analyze_embeddings() takes 2 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "saving_add = \"./analysis/\"\n",
    "seqs_path = \"../data/Test2.fasta\"\n",
    "scoring = MODELS_LIST[0] # ProtT5\n",
    "alignment_type = ALIGNMENT_TYPES[0] # Global\n",
    "\n",
    "# Analysis\n",
    "print(analyze_embeddings(seqs_path, scoring))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Dq9u86RyHKk_",
    "8LCdgRFBFWW6",
    "8ctdjBhTGi9z",
    "wiNZQ2SQJM54",
    "9IMkkTPWsaF0"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
